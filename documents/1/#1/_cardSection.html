<section class="projects">
  <div class="container">
    <h2 class="title projects__title">TrainSet Academy</h2>

    <div class="cardSection">
      <div class="navigationSlider">
        <div class="navigationSlider__arrow swiper-button-prev"></div>

        <div class="navigationSlider__container swiper-container">
          <div class="navigationSlider__wrapper swiper-wrapper">
            <a href="#" class="navigationSlider__link swiper-slide active">Doks</a>
            <a href="#" class="navigationSlider__link swiper-slide">Blog</a>
            <a href="#" class="navigationSlider__link swiper-slide">Training</a>
          </div>
        </div>

        <div class="navigationSlider__arrow swiper-button-next"></div>
      </div>
      @@include("./_tableOfContent.html")

      <h6 class="cardSection__title">Overview</h6>

      <p class="paragraph__text">
        Machine Learning is divided by <span class="paragraph__text_bold">2</span> sub-fields:
        <span class="paragraph__text_bold">supervised</span> and <span class="paragraph__text_bold">unsupervised</span> learning,
        both related to data you use to build a model.
      </p>

      <ul class="paragraph__list paragraph__list_dots-type paragraph__text">
        <li>
          <span class="paragraph__text_bold">In supervised learning</span>, the data you use is labelled, i.e. it has a target
          variable you need to predict, given the response variables . For example, predicting price of an apartment, given such
          variables as: squared footage, number of rooms, district, area, number of schools nearby, etc.
        </li>

        <li>
          <span class="paragraph__text_bold"> In unsupervised learning,</span> the data you use is unlabelled, i.e. it does not
          have a target variable Y. An example of supervised learning is grouping your customers by segment, based on their
          characteristics (response variables).
        </li>
      </ul>

      <div class="paragraph cardSection__paragraph">
        <p class="paragraph__text">To get a little bit ahead, let’s view on the ML Mindmap, and further dissect it!</p>
      </div>

      <h6 class="cardSection__title">Supervised Learning</h6>

      <div class="paragraph cardSection__paragraph">
        <p class="paragraph__text">Supervised learning is divided into two types of algorithms:</p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">Classification algorithms:</h6>

        <p class="paragraph__text">
          Algorithms that predict a category. Examples can be, an algorithm predicting a movie rating: “Best”, “Good”, “Bad”,
          “Worst”; an algorithm predicting a fruit: ‘Banana’, ‘Apple’, ‘Orange’; an algorithm predicting any simple yes-no
          question: “Yes” or “No”, etc.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">Regression algorithms: algorithms:</h6>

        <p class="paragraph__text">
          Algorithms that predict a continuous value, such as “dollars” or “weight”. Examples can be, an algorithm predicting a
          price for the appartment; an algorithm predicting a weight of a person.
        </p>
      </div>

      <h6 class="cardSection__title">Unsupervised Learning</h6>

      <div class="paragraph cardSection__paragraph">
        <p class="paragraph__text">Unsupervised learning is divided into two types of algorithms:</p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">Clustering algorithms: algorithms:</h6>

        <p class="paragraph__text">
          Algorithms that group data based on common characterists that the model would find in the dataset. Examples can be, an
          algorithm segmenting customers in a market.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">Generation algorithms:</h6>

        <p class="paragraph__text">
          AlgAlgorithms that generates data, it mostly related to Natural Language Processing, e.g. generating text.
        </p>
      </div>

      <!--       <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">Regression algorithms: algorithms:</h6>

        <p class="paragraph__text">
          Algorithms that predict a continuous value, such as “dollars” or “weight”. Examples can be, an algorithm predicting a
          price for the appartment; an algorithm predicting a weight of a person.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">3. Cross-Validation</h6>

        <p class="paragraph__text">
          1.It is crucially important, that before moving to CV, you split your data into the train and test sets. In this case,
          after you are done with model selection, you will be able to get an unbiased estimate of model performance on unseen
          data.
        </p>

        <p class="paragraph__text">
          2.Often times I see people do all the data preprocessing prior to CV. However, in this case such phenomenon as
          <a href="https://machinelearningmastery.com/data-leakage-machine-learning/" class="paragraph__text_link"
            >data leakage
          </a>
          can be introduced. The general rule here can be summarized in two points:
        </p>

        <ol class="paragraph__list paragraph__list_inner paragraph__list_lower-alpha">
          <li class="paragraph__text">
            All the <span class="paragraph__text_bold">row-wise transformations</span> (when for each transformation you need to
            know just one value, but not the values of the whole column) can be performed
            <span class="paragraph__text_bold">outside CV loop.</span>
            <span class="paragraph__text_blue">Examples:</span> converting kilometers to meters; transforming “full_name” into
            “first_name” and “last_name”.
          </li>

          <li class="paragraph__text">
            All the <span class="paragraph__text_bold">column-wise transformations</span> (when for each transformation you need
            to know the values of the whole column) should be performed
            <span class="paragraph__text_bold">inside CV loop.</span>
            <span class="paragraph__text_blue">Examples:</span> standardization (because you need to calculate mean and standard
            deviation); rank transformation.
          </li>
        </ol>

        <p class="paragraph__text">
          However, <span class="paragraph__text_bold">transforming data inside CV loop</span> can significantly
          <span class="paragraph__text_bold">slow down</span> the whole process. Thus, the smart approach would be to perform as
          much data preprocessing prior to CV as possible.
        </p>

        <p class="paragraph__text">
          For example, if we look at standardization we need to compute the mean and standard deviation of the whole column.
          However, if the dataset is big enough and we shuffle the data prior to subsetting it into folds, we can assume that data
          from different folds come from the same distribution, and thus it has the same mean and standard deviation across
          different subsets. In this case, even a
          <span class="paragraph__text_bold">column-wise transformation</span>
          can be performed outside CV loop. transformation can be performed outside CV loop.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">4. Cross-Validation Methods</h6>

        <p class="paragraph__text">
          In this section for simplicity we will stick to just one model (LGBMRegressor) and use cross-validation to select its
          hyperparameters. For the sake of hyperparameters space visualization we will tune just two parameters (_max_depth_ and
          _learning_rate)._ We will consider the most popular methods for performing CV as well as some less popular ones that are
          very powerful.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title">4.1 Grid Search CV</h6>

        <p class="paragraph__text">
          <a class="paragraph__text_link" href="https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search"
            >Grid Search CV</a
          >
          performs an exhaustive search over the specified range of hyperparameters (grid). For this method you need to specify
          every single value for each parameter (which can be tricky, especially for the continuous parameters) that you want your
          model to try.
        </p>

        <div class="nestedPicture cardSection__nestedPicture">
          <div class="nestedPicture__image"><img src="./resources/images/academy/1.png" alt="#" /></div>
          <p class="paragraph__text">Figure 2. Randomized Search CV Hyperparameters Space Example</p>
        </div>

        <div class="gistFrame">
          <script src="https://gist.github.com/v-popov/703a560b5eb6e2a47be4bf74f0590768.js"></script>
          <p class="gistFrame__text paragraph__text">Snippet 2. Grid Search CV Code Example</p>
        </div>

        <p class="paragraph__text">
          As you can see from Snippet 2 (cell 11), the best_score has a negative value. It happened because the metric we pass to
          GridSearchCV is Negative MSE (“neg_mean_squared_error”).
        </p>

        <p class="paragraph__text">
          One of the <span class="paragraph__text_bold">major downsides</span> of Grid Search CV is that it can be the case, that
          for example _learning_rate_\=0.45 always leads to terrible performance no matter what values other parameters have, but
          in the example above the value of _learning_rate_\=0.45 is still used 5 times (see
          <span class="paragraph__text_bold">Figure 1</span>) which leads to basically
          <span class="paragraph__text_bold">wasting of these 5 trials.</span>
        </p>

        <p class="paragraph__text">
          Another <span class="paragraph__text_bold">disadvantage</span> of Grid Search CV is that it suffers when it comes to
          dimensionality, as each additional hyperparameter leads to exponential growth of hyperparameters space.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title">4.2 Randomized Search CV</h6>

        <p class="paragraph__text">
          In contrast to Grid Search CV,
          <a
            class="paragraph__text_link"
            href="https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization"
            >Randomized Search CV
          </a>
          <span class="paragraph__text_bold">doesn’t set up a grid</span> of hyperparameter values. Instead, we have to
          <span class="paragraph__text_bold">specify a distribution</span> for each hyperparameter we want to tune. Randomized
          Search CV then sample values from these distributions and selects their random combinations. This allows you to
          explicitly <span class="paragraph__text_bold">the number of parameter combinations</span> that are attempted. The number
          of search iterations is set based on time requirements or available resources.
        </p>

        <div class="nestedPicture cardSection__nestedPicture">
          <div class="nestedPicture__image"><img src="./resources/images/academy/2.png" alt="#" /></div>
          <p class="paragraph__text">Figure 2. Randomized Search CV Hyperparameters Space Example</p>
        </div>

        <div class="gistFrame">
          <script src="https://gist.github.com/v-popov/91b57dbeb2dc519f98e5a7f134e5e152.js"></script>
          <p class="gistFrame__text paragraph__text">Snippet 3. Randomized Search CV Code Example</p>
        </div>

        <p class="paragraph__text">
          As you can see from Snippet 2 (cell 11), the best_score has a negative value. It happened because the metric we pass to
          GridSearchCV is Negative MSE (“neg_mean_squared_error”).
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title">4.3 Bayesian Methods</h6>

        <p class="paragraph__text">
          Both Grid Search CV and Randomized Search CV perform different trials independently. That is why the next set of
          hyperparameters is selected in so-called uninformed manner, meaning we are not using the history of the past trials to
          select the next set of hyperparameters.
        </p>

        <p class="paragraph__text">
          However, more advanced approaches are using the history of past trials to select hyperparameters for each trial in an
          informed manner. This often results in the faster hyperparameter tuning process and more accurate resulting models.
        </p>

        <p class="paragraph__text">
          I will provide examples of two of these methods: Hyperopt and Optuna. You can read more about them here and here
          respectively.
        </p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title">4.3.1 Hyperopt</h6>

        <div class="nestedPicture cardSection__nestedPicture">
          <div class="nestedPicture__image"><img src="./resources/images/academy/3.png" alt="#" /></div>
          <p class="paragraph__text">Figure 3. Hyperopt Hyperparameters Space Example</p>
        </div>

        <p class="paragraph__text">
          Take a look at the color bar in the right part of the graph. It indicates the dynamic of hyperparameters combinations
          selection. You can see that it converges at _max_depth_\=3 and _learning_rate_≈0.20. Note, that for Grid Search CV and
          Randomized CV we didn’t plot the color bar, because in those cases all the trials were performed independently.
        </p>
      </div>

      <div class="gitFrame cardSection__paragraph">
        <script src="https://gist.github.com/v-popov/d17e848bd58513119533a82e2952e4d1.js"></script>
        <p class="gitFrame__text paragraph__text">Snippet 4. Hyperopt Code Example</p>
      </div>

      <div class="paragraph cardSection__paragraph">
        <h6 class="paragraph__title paragraph__title_BG">5. Conclusion</h6>

        <p class="paragraph__text">
          In this article we’ve discussed some important details about Cross-Validation procedures, as well as some of the most
          popular methods for performing it. As a bonus for those who were determined enough and made it to the end of the
          article, here are some useful links:
        </p>

        <ul class="paragraph__list paragraph__list_dots-type">
          <li>
            <a
              href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules"
              class="paragraph__text paragraph__text_link"
              >Predefined sklearn evaluation metrics
            </a>
          </li>

          <li>
            <a href="https://docs.scipy.org/doc/scipy/reference/stats.html" class="paragraph__text paragraph__text_link"
              >Scipy distributions
            </a>
          </li>

          <li>
            <a
              href="https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions"
              class="paragraph__text paragraph__text_link"
              >Hyperopt parameter expressions
            </a>
          </li>
          <li><a href="" class="paragraph__text paragraph__text_link">Optuna suggest options </a></li>
        </ul>
      </div> -->
    </div>
    @@include("./_author.html") @@include("./_fixedArrow.html")
  </div>
</section>
