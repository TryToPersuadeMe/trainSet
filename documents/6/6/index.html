<!DOCTYPE html><html lang="ru">  <head>    <meta charset="UTF-8" />    <meta name="viewport" content="width=device-width, initial-scale=1.0" />    <meta name="format-detection" content="telephone=no" />    <meta name="keywords" content="ключевые слова" />    <meta name="description" content="крутой сайт" />    <link href="./resources/favicon.ico" rel="shortcut icon" type="image/x-icon" />    <link rel="stylesheet" href="./css/main.css" />    <script  async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>    <title>Train Set - Главная страница</title>  </head>  <body>    <div class="wrapper" id="startPage">      <div class="container responsiveHeader">  <a href="/" class="header__logo">    <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>  </a>  <div class="burgerIcon"><span></span></div></div><header class="header">  <div class="container header__container">    <a href="/" class="header__logo">      <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>    </a>    <nav class="header__navigation">      <a href="#" class="link">Academy</a>      <a href="#" class="link link_animatedBG">Projeсts</a>      <a href="#" class="link">Contact</a>    </nav>    <div class="header__authorization">      <a href="https://trytopersuademe.github.io/trainSet/authorization/" class="link link_border">Sign in</a>      <a href="#" class="link link_border">Get Started</a>    </div>  </div></header>      <main><section class="projects">  <div class="container">    <h2 class="title projects__title">TrainSet Academy</h2>    <div class="cardSection">      <div class="navigationSlider">        <div class="navigationSlider__arrow swiper-button-prev"></div>        <div class="navigationSlider__container swiper-container">          <div class="navigationSlider__wrapper swiper-wrapper">            <a href="#" class="navigationSlider__link swiper-slide active">Doks</a>            <a href="#" class="navigationSlider__link swiper-slide">Blog</a>            <a href="#" class="navigationSlider__link swiper-slide">Training</a>          </div>        </div>        <div class="navigationSlider__arrow swiper-button-next"></div>      </div>      <div class="navUlListContetnt">  <h2 class="navUlListContetnt__title">SUPERVISED LEARNING</h2>  <div class="navUlListContetnt__row">    <div class="navUlListContetnt__linksWrapper">      <p class="navUlListContetnt__link navUlListContetnt__link_big">CLASSIFICATION</p>      <a href="#" class="navUlListContetnt__link">Random Forest </a>      <a href="#" class="navUlListContetnt__link">Decision Tree (ID3) </a>      <a href="#" class="navUlListContetnt__link">Logistic Regression</a>      <p class="navUlListContetnt__link navUlListContetnt__link_active">Naive Bayes Classifier</p>      <a href="#" class="navUlListContetnt__link">Decision Tree (CART)</a>      <a href="#" class="navUlListContetnt__link">Linear SVMs </a>      <a href="#" class="navUlListContetnt__link">Kernelized SVMs </a>      <a href="#" class="navUlListContetnt__link">Convulational Neural Nets </a>      <a href="#" class="navUlListContetnt__link">Gradient Boosted Machines </a>    </div>    <h6 class="cardSection__title navUlListContetnt__responsiveTitle-js">Naive Bayes Classifier</h6>    <div class="author">  <div class="author__image">    <picture><source srcset="./resources/images/academy/avatar_1.webp" type="image/webp"><img src="./resources/images/academy/avatar_1.png" alt="Andrew Wolf" /></picture>  </div>  <div class="author__column">    <p class="author__text">Written by <span class="author__text_bold">Victor Popov</span></p>    <p class="author__text">Feb 29, 2020</p>  </div></div>  </div></div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">1. Introduction</h6>        <p class="paragraph__text">          Naive Bayes is so ‘naive’ because it assumes that all of the features in a data set are equally important and          independent. These assumptions are rarely true in real world scenario, however Naive Bayes algorithm sometimes performs          surprisingly well. This is the supervised learning algorithm used for both classification and regression. Its advantage          is that it requires very small computational power and as a result works fast even with large data.        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">2. Key Terms</h6>        <ul class="paragraph__list paragraph__list_dots-type paragraph__text">          <li>Prior probability is the proportion of dependent variable (target) in the data set.</li>          <li>            Likelihood is the probability of particular classification a given observation in presence of some other variable.          </li>          <li>Marginal likelihood is the proportion of independent variable (predictor) in the data set.</li>        </ul>        <p class="paragraph__text">          These terms might not be clear to you. Let’s dive into an example that shows what exactly Naive Bayes does, with an          indication of these terms.        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">3. Example with Explanation</h6>        <p class="paragraph__text">          Below I have a training data set of weather and corresponding target variable ‘Play’ (suggesting possibilities of          playing). Now, we need to classify whether players will play or not based on weather condition. Let’s follow the below          steps to perform Naive Bayes:        </p>        <ul class="paragraph__list paragraph__list_dots-type paragraph__text">          <li>Step 1: Convert the data set into a frequency table (also called contingency table)</li>          <li>Step 2: Create Likelihood table.</li>          <li>            Step 3: Use Naive Bayesian equation to calculate the posterior probability for each class. The class with the highest            posterior probability is the outcome of prediction.          </li>        </ul>        <p class="paragraph__text paragraph__text_bold paragraph__text_big">3.1. Step 1 and Step 2</p>        <p class="paragraph__text">          Let’s go over the first two steps. These steps will also help us understand prior probability, likelihood and marginal          likelihood.        </p>        <div class="nestedPicture cardSection__nestedPicture">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/1.webp" type="image/webp"><img src="./resources/images/academy/1.png" alt="#" /></picture></div>        </div>        <p class="paragraph__text">          The terms Likelihood, Marginal Likelihood, and Prior Probability (or Class Prior Probability, as it is related to          classes “Yes” or “No”) that were mentioned above are shown below        </p>        <div class="nestedPicture cardSection__nestedPicture">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/2.webp" type="image/webp"><img src="./resources/images/academy/2.png" alt="#" /></picture></div>        </div>        <p class="paragraph__text">So, we can now see that:</p>        <ul class="paragraph__list paragraph__list_dots-type paragraph__text">          <li>Likelihood = P (Feature & #124 Class)</li>          <li>Marginal Likelihood = P (Feature)</li>          <li>Prior Likelihood = P (Class)</li>        </ul>        <p class="paragraph__text">          Likelihood is just a probability of a feature within a class. For example, if we want to calculate P(Sunny $$ $$ “Yes”),          where Sunny is a feature, and “Yes” is a class, we will count all “Yes”es, or all times we went to Play, (and ignore          “No”s) when we had “Sunny” weather, divided by the overall observed days in our data set.        </p>        <p class="paragraph__text">          Marginal Likelihood is a probability of a feature. For example, if we want to calculate P(Sunny), we will count all the          Sunny days divided by the overall observed days in our data set.        </p>        <p class="paragraph__text">          Prior Likelihood or Class Prior Probability is a probability of a class. For example, if we want to calculate P(“No”),          we will count all the “No”s, or, the days we did not go to Play, divided by the overall observed days in our data set.        </p>        <p class="paragraph__text">          Posterior probability is the revised probability of an event occurring after taking into consideration new information.          It will be discussed in more details later in this article.        </p>        <p class="paragraph__text paragraph__text_bold paragraph__text_big">3.2. Step 3</p>        <p class="paragraph__text">          Use Bayes’ Formula to calculate the posterior probability for each class. The class with the highest posterior          probability is the outcome of prediction.        </p>        <div class="nestedPicture cardSection__nestedPicture">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/3.webp" type="image/webp"><img src="./resources/images/academy/3.png" alt="#" /></picture></div>        </div>        <p class="paragraph__text">          In formula above ’c’ denotes class and ’x’ denotes features. Next, let’s look at P(x). As you can see, the denominator          contains the only term that is a function of the data (features) - it is not a function of the class we are currently          looking at. Thus, it will be the same for all the classes. Traditionally in Naive Bayes Classification, we drop this          denominator as it does not impact the final outcome of the classifier in order to make the prediction:        </p>        <p class="paragraph__text">||</p>        <p class="paragraph__text">To make it more interesting, let’s assume we have an the additional feature - Wind:</p>        <div class="nestedPicture cardSection__nestedPicture">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/4.webp" type="image/webp"><img src="./resources/images/academy/4.png" alt="#" /></picture></div>        </div>        <p class="paragraph__text">Let’s assume we want to predict the class for the data with the following features:</p>        <p class="paragraph__text">          In order to make a prediction we need to compare posterior probabilities for each class after observing the input data.          For this purpose we will use the expression (1). Do not forget, that Naive Bayes assumes independence of features. In          order not to inflate our formulas we will use the following notation: ’X1’ for ’Weather’, ’X2’ for ’Wind’ and ’C’ for          ’Class’        </p>        <p class="paragraph__text">          First, we estimate the probability for going to Play (i.e. the class = “Yes”) for Wind = Moderate, Weather = Sunny:        </p>        <p class="paragraph__text">TBD….</p>      </div>    </div>    <div class="fixedArrow">      <a href="#startPage" class="fixedArrow__arrow">up</a>    </div>  </div></section></main>      <footer class="footer">  <div class="footer__wrapper">    <div class="footer__row">      <a href="#" class="footer__link">Home</a>      <a href="#" class="footer__link">Blog</a>      <a href="#" class="footer__link">Contact</a>    </div>    <div class="footer__row">      <a href="https://www.facebook.com/thelearningm" class="footer__socialMedia"  target="_blank"><picture><source srcset="./resources/icons/facebook-icon.svg" type="image/webp"><img src="./resources/icons/facebook-icon.svg" alt="facebook" /></picture></a>      <a href="https://www.instagram.com/thelearningm" target="_blank" class="footer__socialMedia"><picture><source srcset="./resources/icons/instagram-icon.svg" type="image/webp"><img src="./resources/icons/instagram-icon.svg" alt="instagram" /></picture></a>    </div>  </div></footer>    </div>    <!-- swiper -->    <script src="./js/js__plugins/swiper-bundle.min.js"></script>    <!-- main js -->    <script src="./js/main.js"></script>  </body></html>