<!DOCTYPE html><html lang="ru">  <head>    <meta charset="UTF-8" />    <meta name="viewport" content="width=device-width, initial-scale=1.0" />    <meta name="format-detection" content="telephone=no" />    <meta name="keywords" content="ключевые слова" />    <meta name="description" content="крутой сайт" />    <link href="./resources/favicon.ico" rel="shortcut icon" type="image/x-icon" />    <link rel="stylesheet" href="./css/main.css" />    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>    <title>Train Set - Главная страница</title>  </head>  <body>    <div class="wrapper" id="startPage">      <div class="container responsiveHeader">  <a href="/" class="header__logo">    <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>  </a>  <div class="burgerIcon"><span></span></div></div><header class="header">  <div class="container header__container">    <a href="/" class="header__logo">      <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>    </a>    <nav class="header__navigation">      <a href="#" class="link">Academy</a>      <a href="#" class="link link_animatedBG">Projeсts</a>      <a href="#" class="link">Contact</a>    </nav>    <div class="header__authorization">      <a href="https://trytopersuademe.github.io/trainSet/authorization/" class="link link_border">Sign in</a>      <a href="#" class="link link_border">Get Started</a>    </div>  </div></header>      <main><section class="projects">  <div class="container">    <h2 class="title projects__title">TrainSet Academy</h2>    <div class="cardSection">      <div class="navigationSlider">        <div class="navigationSlider__arrow swiper-button-prev"></div>        <div class="navigationSlider__container swiper-container">          <div class="navigationSlider__wrapper swiper-wrapper">            <a href="#" class="navigationSlider__link swiper-slide active">Doks</a>            <a href="#" class="navigationSlider__link swiper-slide">Blog</a>            <a href="#" class="navigationSlider__link swiper-slide">Training</a>          </div>        </div>        <div class="navigationSlider__arrow swiper-button-next"></div>      </div>      <div class="navUlListContetnt">  <h2 class="navUlListContetnt__title">SUPERVISED LEARNING</h2>  <div class="navUlListContetnt__row">    <div class="navUlListContetnt__linksWrapper">      <p class="navUlListContetnt__link navUlListContetnt__link_big">REGRESSION</p>      <a href="#" class="navUlListContetnt__link">Lasso, Ridge & Elastic Net</a>      <p class="navUlListContetnt__link navUlListContetnt__link_active">Linear Regression</p>      <a href="#" class="navUlListContetnt__link">KNN Regression</a>      <a href="#" class="navUlListContetnt__link">Multivariate Regression</a>      <a href="#" class="navUlListContetnt__link">Neural Network Regressor</a>      <a href="#" class="navUlListContetnt__link">Polynomial Regression</a>    </div>    <h6 class="cardSection__title navUlListContetnt__responsiveTitle-js">Lasso, Ridge & Elastic Net</h6>    <div class="author">  <div class="author__image">    <picture><source srcset="./resources/images/academy/avatar_1.webp" type="image/webp"><img src="./resources/images/academy/avatar_1.png" alt="Andrew Wolf" /></picture>  </div>  <div class="author__column">    <p class="author__text">Written by <span class="author__text_bold">Victor Popov</span></p>    <p class="author__text">Feb 29, 2020</p>  </div></div>  </div></div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">1. Introduction to Lasso Regularization Term (L1)</h6>        <p class="paragraph__text">          LASSO - Least Absolute Shrinkage and Selection Operator - was first formulated by Robert Tibshirani in 1996. It is a          powerful method that performs two main tasks: regularization and feature selection.        </p>        <p class="paragraph__text">          Let’s look at the example of lasso regularization with linear models, where OLS method is used with its regularization          term.        </p>        <div class="nestedPicture cardSection__nestedPicture nestedPicture_math-code">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/1.webp" type="image/webp"><img src="./resources/images/academy/1.png" alt="#" /></picture></div>        </div>        <p class="paragraph__text">          The LASSO method puts a constraint on the sum of the absolute values of the model parameters, the sum has to be less          than a fixed value (upper bound, or ):        </p>        <div class="paragraph__text paragraph__text_math-code">          <math class="paragraph__text paragraph__text_math-code" xmlns="http://www.w3.org/1998/Math/MathML" display="block">            <munderover>              <mo>&#x2211;<!-- ∑ --></mo>              <mrow class="MJX-TeXAtom-ORD">                <mi>k</mi>              </mrow>              <mrow class="MJX-TeXAtom-ORD">                <mi>j</mi>                <mo>=</mo>                <mn>1</mn>              </mrow>            </munderover>            <mrow>              <mo>|</mo>              <msub>                <mi>&#x03B2;<!-- β --></mi>                <mrow class="MJX-TeXAtom-ORD">                  <mi>j</mi>                </mrow>              </msub>              <mo>|</mo>            </mrow>            <mo>&lt;</mo>            <mi>t</mi>            <mo>,</mo>          </math>        </div>        <p class="paragraph__text">–where t is the upper bound for the sum of the coefficients.</p>        <p class="paragraph__text">          In order to do so, the method applies a shrinking (regularization) process where it penalizes the coefficients of the          regression variables shrinking some of them to zero. During features selection process the variables that still have a          non-zero coefficient after the shrinking process are selected to be part of the model. The goal of this process is to          minimize the prediction error.        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">2. Parameter alpha ()</h6>        <div class="paragraph__text paragraph__text_math-code">          <math class="paragraph__text paragraph__text_math-code" xmlns="http://www.w3.org/1998/Math/MathML" display="block">            <mi>&#x03B1;<!-- α --></mi>          </math>        </div>        <p class="paragraph__text">          In practice, the tuning parameter α that controls the strength of the penalty assumes great importance. Indeed, when α          is sufficiently large, coefficients are forced to be exactly equal to zero. This way, dimensionality can be reduced. The          larger the parameter α, the more the number of coefficients are shrunk to zero. On the other hand, if α = 0, we have          just an OLS (Ordinary Least Squares) regression.        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">3. Advanages</h6>        <p class="paragraph__text">There are many advantages of using the LASSO method.</p>        <ul class="paragraph__list paragraph__text paragraph__list_dots-type">          <li>            First of all, it can provide a very good prediction accuracy, because shrinking and removing the coefficients can            reduce variance without a substantial increase of the bias, this is especially useful when you have a small number of            observation and a large number of features. In terms of the tuning parameter α we know that bias increases and            variance decreases when α increases, indeed a trade-off between bias and variance has to be found.          </li>          <li>            Moreover, the LASSO helps to increase the model interpretability by eliminating irrelevant variables that are not            associated with the response variable, this way also overfitting is reduced. This is the point where we are more            interested in because in this paper the focus is on the feature selection task.          </li>        </ul>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">4. Introduction to Lasso Regression</h6>        <p class="paragraph__text">          Lasso with linear models is called Lasso Regression. It is the model that describes the relationship between response          variable Y and explanatory variables X. In the case of one explanatory variable, Lasso Regression is called Simple Lasso          Regression while the case with two or more explanatory variables is called Multiple Lasso Regression.        </p>        <p class="paragraph__text">Lasso Regression holds all the assumptions of the Linear Regression, such as:</p>        <ul class="paragraph__list paragraph__text paragraph__list_dots-type">          <li>The response variable is normally distributed;</li>          <li>There is a linear relationship between the response variable and the explanatory variables;</li>          <li>            The random errors are normally distributed, have constant (equal) variances at any point in X, and are independent.          </li>        </ul>        <div>          <p class="paragraph__text">            <span class="paragraph__text_italic">To read more about Linear Regression assumptions</span>, go to            <a href="https://www.thelearningmachine.ai/cnn" class="paragraph__text_link">Linear Regression</a>          </p>        </div>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">5. The Model</h6>        <p class="paragraph__text">          The LASSO minimizes the sum of squared errors, with an upper bound on the sum of the absolute values of the model          parameters. The lasso estimate is defined by the solution to the L1 optimization problem:        </p>        <div class="paragraph__text paragraph__text_math-code">          <math class="paragraph__text paragraph__text_math-code" xmlns="http://www.w3.org/1998/Math/MathML" display="block">            <mo>&lt;</mo>            <mi>i</mi>            <mo>&gt;</mo>            <mi>m</mi>            <mi>i</mi>            <mi>n</mi>            <mi>i</mi>            <mi>m</mi>            <mi>i</mi>            <mi>z</mi>            <mi>e</mi>            <mo>&lt;</mo>            <mrow class="MJX-TeXAtom-ORD">              <mo>/</mo>            </mrow>            <mi>i</mi>            <mo>&gt;</mo>            <mrow>              <mo>[</mo>              <mfrac>                <mrow>                  <munderover>                    <mo>&#x2211;<!-- ∑ --></mo>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>&#x0131;<!-- ı --></mi>                      <mo>=</mo>                      <mn>1</mn>                    </mrow>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>n</mi>                    </mrow>                  </munderover>                  <mo stretchy="false">(</mo>                  <msub>                    <mi>y</mi>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>i</mi>                    </mrow>                  </msub>                  <mo>&#x2212;<!-- − --></mo>                  <mo stretchy="false">)</mo>                  <mo stretchy="false">(</mo>                  <msub>                    <mi>&#x03B2;<!-- β --></mi>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>i</mi>                    </mrow>                  </msub>                  <msub>                    <mi>x</mi>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>i</mi>                    </mrow>                  </msub>                  <mo>+</mo>                  <msub>                    <mi>&#x03B2;<!-- β --></mi>                    <mrow class="MJX-TeXAtom-ORD">                      <mn>0</mn>                    </mrow>                  </msub>                  <mo stretchy="false">)</mo>                  <msup>                    <mo stretchy="false">)</mo>                    <mn>2</mn>                  </msup>                </mrow>                <mi>n</mi>              </mfrac>              <mo>]</mo>            </mrow>            <mo>&lt;</mo>            <mi>i</mi>            <mo>&gt;</mo>            <mi>s</mi>            <mi>u</mi>            <mi>b</mi>            <mi>j</mi>            <mi>e</mi>            <mi>c</mi>            <mi>t</mi>            <mi>t</mi>            <mi>o</mi>            <mo>&lt;</mo>            <mrow class="MJX-TeXAtom-ORD">              <mo>/</mo>            </mrow>            <mi>i</mi>            <mo>&gt;</mo>            <mrow>              <mo>[</mo>              <mrow>                <mi>&#x03B1;<!-- α --></mi>                <munderover>                  <mo>&#x2211;<!-- ∑ --></mo>                  <mrow class="MJX-TeXAtom-ORD">                    <mi>&#x0237;<!-- ȷ --></mi>                    <mo>=</mo>                    <mn>1</mn>                  </mrow>                  <mrow class="MJX-TeXAtom-ORD">                    <mi>k</mi>                  </mrow>                </munderover>                <mrow>                  <mo>|</mo>                  <msub>                    <mi>&#x03B2;<!-- β --></mi>                    <mrow class="MJX-TeXAtom-ORD">                      <mi>&#x0237;<!-- ȷ --></mi>                    </mrow>                  </msub>                  <mo>|</mo>                </mrow>                <mo>&lt;</mo>                <mi>t</mi>              </mrow>              <mo>]</mo>            </mrow>            <mo>,</mo>          </math>        </div>      </div>    </div>    <div class="fixedArrow">      <a href="#startPage" class="fixedArrow__arrow">up</a>    </div>  </div></section></main>      <footer class="footer">  <div class="footer__wrapper">    <div class="footer__row">      <a href="#" class="footer__link">Home</a>      <a href="#" class="footer__link">Blog</a>      <a href="#" class="footer__link">Contact</a>    </div>    <div class="footer__row">      <a href="https://www.facebook.com/thelearningm" class="footer__socialMedia"  target="_blank"><picture><source srcset="./resources/icons/facebook-icon.svg" type="image/webp"><img src="./resources/icons/facebook-icon.svg" alt="facebook" /></picture></a>      <a href="https://www.instagram.com/thelearningm" target="_blank" class="footer__socialMedia"><picture><source srcset="./resources/icons/instagram-icon.svg" type="image/webp"><img src="./resources/icons/instagram-icon.svg" alt="instagram" /></picture></a>    </div>  </div></footer>    </div>    <!-- swiper -->    <script src="./js/js__plugins/swiper-bundle.min.js"></script>    <!-- main js -->    <script src="./js/main.js"></script>  </body></html>