<!DOCTYPE html><html lang="ru">  <head>    <meta charset="UTF-8" />    <meta name="viewport" content="width=device-width, initial-scale=1.0" />    <meta name="format-detection" content="telephone=no" />    <meta name="keywords" content="ключевые слова" />    <meta name="description" content="крутой сайт" />    <link href="./resources/favicon.ico" rel="shortcut icon" type="image/x-icon" />    <link rel="stylesheet" href="./css/main.css" />    <script  async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>    <title>Train Set - Главная страница</title>  </head>  <body>    <div class="wrapper" id="startPage">      <div class="container responsiveHeader">  <a href="/" class="header__logo">    <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>  </a>  <div class="burgerIcon"><span></span></div></div><header class="header">  <div class="container header__container">    <a href="/" class="header__logo">      <picture><source srcset="./resources/images/logotype.svg" type="image/webp"><img src="./resources/images/logotype.svg" alt="логотип Train Set" /></picture>    </a>    <nav class="header__navigation">      <a href="#" class="link">Academy</a>      <a href="#" class="link link_animatedBG">Projeсts</a>      <a href="#" class="link">Contact</a>    </nav>    <div class="header__authorization">      <a href="https://trytopersuademe.github.io/trainSet/authorization/" class="link link_border">Sign in</a>      <a href="#" class="link link_border">Get Started</a>    </div>  </div></header>      <main><section class="projects">  <div class="container">    <h2 class="title projects__title">TrainSet Academy</h2>    <div class="cardSection">      <div class="navigationSlider">        <div class="navigationSlider__arrow swiper-button-prev"></div>        <div class="navigationSlider__container swiper-container">          <div class="navigationSlider__wrapper swiper-wrapper">            <a href="#" class="navigationSlider__link swiper-slide active">Doks</a>            <a href="#" class="navigationSlider__link swiper-slide">Blog</a>            <a href="#" class="navigationSlider__link swiper-slide">Training</a>          </div>        </div>        <div class="navigationSlider__arrow swiper-button-next"></div>      </div>      <div class="navUlListContetnt">  <h2 class="navUlListContetnt__title">UNSUPERVISED LEARNING</h2>  <div class="navUlListContetnt__row">    <div class="navUlListContetnt__linksWrapper">      <p href="#" class="navUlListContetnt__link navUlListContetnt__link_big">CLUSTERING</p>      <p href="#" class="navUlListContetnt__link navUlListContetnt__link_active">K-Means </p>      <a href="#" class="navUlListContetnt__link">K-Medians</a>      <a href="#" class="navUlListContetnt__link">K-Medoids </a>      <a href="#" class="navUlListContetnt__link">Fuzzy C-Means </a>      <a href="#" class="navUlListContetnt__link"> Hierarchial Clustering</a>    </div>    <h6 class="cardSection__title navUlListContetnt__responsiveTitle-js">K-Means</h6>    <div class="author">  <div class="author__image">    <picture><source srcset="./resources/images/academy/avatar_1.webp" type="image/webp"><img src="./resources/images/academy/avatar_1.png" alt="Andrew Wolf" /></picture>  </div>  <div class="author__column">    <p class="author__text">Written by <span class="author__text_bold">Victor Popov</span></p>    <p class="author__text">Feb 29, 2020</p>  </div></div>  </div></div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">1. Introduction</h6>        <p class="paragraph__text">          Labels are an essential ingredient to supervised algorithms like Support Vector Machines, which learns a hypothesis          function to predict labels given features. K-means clustering is a type of unsupervised learning, which is used when you          have unlabeled data (i.e., data without defined categories/groups/response variables).        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">2. Key Terms</h6>        <ul class="paragraph__text paragraph__list paragraph__list_dots-type">          <li>            <span class="paragraph__text_bold">CLuster:</span> is a collection of data points aggregated together because of            certain similarities.          </li>          <li>            <span class="paragraph__text_bold">CLuster Centroid</span> (or simply            <span class="paragraph__text_bold">centroid</span>) is the mean of a cluster, its values are the coordinate-wise            average of the data points in this cluster.          </li>          <li>            <span class="paragraph__text_bold">Within-Cluster Varianceis</span> the coordinate-wise squared deviations from the            cluster centroid of all the observations belonging to that cluster:          </li>        </ul>        <p class="paragraph__text">          In the expression above denotes j-th predictor of observation ; denotes a set of points belonging to cluster and denotes          a centroid of cluster        </p>        <ul class="paragraph__text paragraph__list paragraph__list_dots-type">          <li>Total Within-Cluster Varianceis a within-cluster variance summed up across all clusters:</li>        </ul>        <p class="paragraph__text">Note that the notation means the euclidean distance between vectors and</p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">3. Data Representation and Preparation</h6>        <p class="paragraph__text">          In the formulas above represents a vector in a P-dimensional space and P is a number of predictors in data set. As you          can see from the formulas above, K-Means algorithm utilizes the notion of distance between data points and each data          point weights equally. In order to calculate the distance, we need our data to be numerical. For this reason,          categorical values should be handled (either excluded from the list of predictors or replaced with numerical values).          Also, we need to normalize our data in order to avoid the effects of incomparable units and different scaling.        </p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">4. Algorithm</h6>        <p class="paragraph__text">          K-Means algorithm finds cluster centers that minimize the total within-cluster variance . This is achieved in several          steps:        </p>        <ul class="paragraph__text paragraph__list paragraph__list_dots-type">          <li><span class="paragraph__text_bold">Step 1:</span> Randomly generate K centroids</li>          <li><span class="paragraph__text_bold">Step 2:</span> Assign data points to the cluster of the closest centroid:</li>          <li><span class="paragraph__text_bold">Step 3:</span> Compute the mean of each cluster</li>          <li>            <span class="paragraph__text_bold">Step 4:</span> Reassign centroids to respective clusters’ means computed in Step 3          </li>          <li><span class="paragraph__text_bold">Step 5:</span> If the stop criterion is not satisfied: Go to Step 2</li>        </ul>        <p class="paragraph__text"><span class="paragraph__text_bold">Stop criterion</span> can be one of the following:</p>        <ol class="paragraph__text paragraph__list paragraph__list_bold-marker">          <li>Cluster re-assignation results in same clusters</li>          <li>A specified number of iterations is reached</li>          <li>Reassigned centroids are located close (need to specify the distance) to the previous centroids</li>        </ol>        <p class="paragraph__text">          In order to achieve <span class="paragraph__text_bold">global optima</span>, the algorithm should be run multiple times          and clusters’ realization that is observed more often will be our global optima.        </p>        <p class="paragraph__text">          Example: In Figure 1, you can see a K-means algorithm. Training examples are shown as dots, and cluster centroids (K)          are shown as crosses. (a) is an original dataset. (b) is a random initial cluster centroids. (c-f) is an illustration of          running two iterations of k-means. In each iteration, we assign each training example to the closest cluster centroid          (shown by ”painting” the training examples the same color as the cluster centroid to which is assigned); then we move          each cluster centroid to the mean of the points assigned to it.        </p>        <div class="nestedPicture cardSection__nestedPicture ">          <div class="nestedPicture__image"><picture><source srcset="./resources/images/academy/1.webp" type="image/webp"><img src="./resources/images/academy/1.png" alt="#" /></picture></div>        </div>        <!-- for space bettween image and text -->        <p class="paragraph__text"></p>      </div>      <div class="paragraph cardSection__paragraph">        <h6 class="paragraph__title paragraph__title_BG">5. Choosing K</h6>        <p class="paragraph__text">There are three most common ways of selecting the number of clusters K.</p>        <ol class="paragraph__text paragraph__list paragraph__list_bold-marker">          <li>            Utilize our domain knowledge or any other insight about the data. For instance, we want to cluster flower and we know            that our data contains exactly 3 types of flowers. Another example is when we want to cluster cars sold last year. In            this case, K will be the number of all car manufacturers available on the market.          </li>          <li>            Run the algorithms several times for different values of K and select such K that results in the smallest value of            total within-cluster variance.          </li>          <li>Perform cross-validation and select such K that performs the best on a hold-out dataset.</li>        </ol>      </div>    </div>    <div class="fixedArrow">      <a href="#startPage" class="fixedArrow__arrow">up</a>    </div>  </div></section></main>      <footer class="footer">  <div class="footer__wrapper">    <div class="footer__row">      <a href="#" class="footer__link">Home</a>      <a href="#" class="footer__link">Blog</a>      <a href="#" class="footer__link">Contact</a>    </div>    <div class="footer__row">      <a href="https://www.facebook.com/thelearningm" class="footer__socialMedia"  target="_blank"><picture><source srcset="./resources/icons/facebook-icon.svg" type="image/webp"><img src="./resources/icons/facebook-icon.svg" alt="facebook" /></picture></a>      <a href="https://www.instagram.com/thelearningm" target="_blank" class="footer__socialMedia"><picture><source srcset="./resources/icons/instagram-icon.svg" type="image/webp"><img src="./resources/icons/instagram-icon.svg" alt="instagram" /></picture></a>    </div>  </div></footer>    </div>    <!-- swiper -->    <script src="./js/js__plugins/swiper-bundle.min.js"></script>    <!-- main js -->    <script src="./js/main.js"></script>  </body></html>